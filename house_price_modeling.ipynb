{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "#Import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "# import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.base import clone\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"./datasets/house-price/\"\n",
    "SAVED_PROCESSED_DF = \"./datasets/house-price/saved_df/\"\n",
    "TRAIN_PATH = os.path.join(SAVED_PROCESSED_DF, \"train_df.csv\")\n",
    "\n",
    "if os.path.exists(os.path.join(ROOT, \"base_model_performances\")):\n",
    "    os.mkdir(os.path.join(ROOT, \"base_model_performances\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 80)\n",
      "(1460,)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "x = train_df.loc[:, train_df.columns != \"SalePrice\"]\n",
    "y = train_df[\"SalePrice\"]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Base Models\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "elastic_net = make_pipeline(RobustScaler(),\n",
    "    ElasticNet(alpha = 0.0005, random_state=1))\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(),\n",
    "    Lasso(alpha = 0.0005, random_state=3))\n",
    "\n",
    "\n",
    "svr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "\n",
    "polynomial_reg = make_pipeline(PolynomialFeatures(degree = 2), LinearRegression())\n",
    "\n",
    "catboost = CatBoostRegressor(\n",
    "    iterations=500,\n",
    "    max_ctr_complexity=4,\n",
    "    random_seed = 0,\n",
    "    od_type = 'Iter',\n",
    "    od_wait=25,\n",
    "    logging_level = \"Silent\",\n",
    "    depth=4\n",
    ")\n",
    "\n",
    "xgboost = XGBRegressor(\n",
    "    max_depth = 8, \n",
    "    n_estimators=500, \n",
    "    min_child_weight = 10000, \n",
    "    colsample_bytree=0.7,\n",
    "    subsample=0.7,eta=0.3, \n",
    "    seed = 0)\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=50, \n",
    "    max_depth=7, \n",
    "    random_state = 0, \n",
    "    n_jobs = -1)\n",
    "\n",
    "knn_model = make_pipeline(\n",
    "    MinMaxScaler(), \n",
    "    KNeighborsRegressor(n_neighbors=9, leaf_size=13, n_jobs=-1))\n",
    "\n",
    "\n",
    "stack_models = [\n",
    "    (\"Linear Regression\", linear_reg),\n",
    "    (\"Catboost\", catboost),\n",
    "    (\"RandomForest\", rf_model),\n",
    "]\n",
    "stacking = StackingRegressor(stack_models, \n",
    "                             final_estimator = clone(linear_reg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  Linear Regression\n",
      "mean  0.13873565268224744\n",
      "std  0.03195972660515161\n",
      "elapsed:  0.15324869300820865  seconds \n",
      "------------------------\n",
      "\n",
      "Model  Elastic Net\n",
      "mean  0.1348940223450052\n",
      "std  0.029674934186491874\n",
      "elapsed:  0.5003467430069577  seconds \n",
      "------------------------\n",
      "\n",
      "Model  Lasso\n",
      "mean  0.1330275310921709\n",
      "std  0.03012838776375157\n",
      "elapsed:  0.4508253039966803  seconds \n",
      "------------------------\n",
      "\n",
      "Model  SVR\n",
      "mean  0.17464087575885698\n",
      "std  0.043730848281039805\n",
      "elapsed:  0.4318600060069002  seconds \n",
      "------------------------\n",
      "\n",
      "Model  Catboost\n",
      "mean  0.1192194863446893\n",
      "std  0.014669824244029375\n",
      "elapsed:  8.025672100993688  seconds \n",
      "------------------------\n",
      "\n",
      "Model  XGBoost\n",
      "mean  0.398246050678286\n",
      "std  0.030270119817323127\n",
      "elapsed:  5.660264181991806  seconds \n",
      "------------------------\n",
      "\n",
      "Model  RandomForest\n",
      "mean  0.14483360468824255\n",
      "std  0.01281024475451813\n",
      "elapsed:  3.4280171599966707  seconds \n",
      "------------------------\n",
      "\n",
      "Model  KNN Regressor\n",
      "mean  0.18211623107658534\n",
      "std  0.012268532133518344\n",
      "elapsed:  1.1887407800095389  seconds \n",
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Setting up KFold\n",
    "\n",
    "models = [\n",
    "    (\"Linear Regression\", LinearRegression()),\n",
    "    (\"Elastic Net\", elastic_net),\n",
    "    (\"Lasso\", lasso),\n",
    "    (\"SVR\", svr),\n",
    "    (\"Catboost\", catboost),\n",
    "    (\"XGBoost\", xgboost),\n",
    "    (\"RandomForest\", rf_model),\n",
    "    (\"KNN Regressor\", knn_model),\n",
    "    (\"Stack Regressor\", stacking)\n",
    "]\n",
    "\n",
    "def measure_performance(model, x, y, k_fold = 10, shuffle = True):\n",
    "    kfold = KFold(n_splits = k_fold, shuffle = shuffle)\n",
    "    rmse_scores = []\n",
    "    r2 = []\n",
    "    for train_index, valid_index in kfold.split(x):\n",
    "        x_train, x_vaild = x.loc[train_index], x.loc[valid_index]\n",
    "        y_train, y_valid = y.loc[train_index], y.loc[valid_index]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_vaild)\n",
    "\n",
    "        rmse_scores.append(rmse(y_valid, y_pred))\n",
    "    return model, rmse_scores\n",
    "\n",
    "model_scores = []\n",
    "\n",
    "for name, model in models:\n",
    "    start = timeit.default_timer()\n",
    "    fitted_model, rmse_scores = measure_performance(model, x,y)\n",
    "    end = timeit.default_timer()\n",
    "    \n",
    "    mean_rmse = np.mean(rmse_scores)\n",
    "    std_rmse = np.std(rmse_scores)\n",
    "    \n",
    "    elapsed = end - start\n",
    "    print(\"Model \", name)\n",
    "    print(\"mean \", mean_rmse)\n",
    "    print(\"std \", std_rmse)\n",
    "    print(\"elapsed: \", elapsed, \" seconds \")\n",
    "    print(\"------------------------\\n\")\n",
    "    model_scores.append({\"name\": name, \"rmse\": rmse_scores, \"elapsed_time\": elapsed})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put everything together and measure the based line\n",
    "\n",
    "#Store the scores\n",
    "def convert_scores_to_pd(scores):\n",
    "    merged = {}\n",
    "    for score in scores:\n",
    "        print(score[\"name\"])\n",
    "        for key, value in score.items():\n",
    "            if key == \"rmse\":\n",
    "                if \"mean\" not in merged:\n",
    "                    merged.setdefault(\"mean\", [np.mean(value)])\n",
    "                else:\n",
    "                    merged[\"mean\"].append(np.mean(value))\n",
    "                if \"std\" not in merged:\n",
    "                    merged.setdefault(\"std\", [np.std(value)])\n",
    "                else:\n",
    "                    merged[\"std\"].append(np.std(value))\n",
    "                continue\n",
    "                \n",
    "            if(key not in merged):\n",
    "                merged.setdefault(key, [value])\n",
    "            else:\n",
    "                merged[key].append(value)\n",
    "    return pd.DataFrame(merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tunning SVR with grid search\n",
    "\n",
    "params = {\n",
    "    \"C\": [.0001 , .001, .01, 1, 10, 100, 1000, 10000],\n",
    "    \"epsilon\": [.0001 , .001, .01, 1, 10, 100, 100],\n",
    "}\n",
    "\n",
    "svr_grid_search = GridSearchCV(SVR(), params, n_jobs = -1, verbose = 50)\n",
    "svr_grid_search.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Measure best SVR\n",
    "print(svr_grid_search.best_estimator_)\n",
    "\n",
    "best_svr = svr_grid_search.best_estimator_\n",
    "\n",
    "best_svr.get_params()\n",
    "\n",
    "start = timeit.default_timer()\n",
    "fitted_model, rmse_scores = measure_performance(best_svr, x,y)\n",
    "end = timeit.default_timer()\n",
    "\n",
    "mean_rmse = np.mean(rmse_scores)\n",
    "std_rmse = np.std(rmse_scores)\n",
    "name = \"SVR Optimized\"\n",
    "elapsed = end - start\n",
    "print(\"Model \", name)\n",
    "print(\"mean \", mean_rmse)\n",
    "print(\"std \", std_rmse)\n",
    "print(\"elapsed: \", elapsed, \" seconds \")\n",
    "model_scores.append({\"name\": name, \"rmse\": rmse_scores, \"elapsed_time\": elapsed})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg = LinearRegression()\n",
    "\n",
    "svr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "\n",
    "catboost = CatBoostRegressor(\n",
    "    iterations=500,\n",
    "    max_ctr_complexity=4,\n",
    "    random_seed = 0,\n",
    "    od_type = 'Iter',\n",
    "    od_wait=25,\n",
    "    logging_level = \"Silent\",\n",
    "    depth=4\n",
    ")\n",
    "\n",
    "xgboost = XGBRegressor(\n",
    "    max_depth = 8, \n",
    "    n_estimators=500, \n",
    "    min_child_weight = 10000, \n",
    "    colsample_bytree=0.7,\n",
    "    subsample=0.7,eta=0.3, \n",
    "    seed = 0)\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=50, \n",
    "    max_depth=7, \n",
    "    random_state = 0, \n",
    "    n_jobs = -1)\n",
    "\n",
    "#Tune stack models\n",
    "stack_models = [\n",
    "    (\"Linear Regression\", LinearRegression()),\n",
    "    (\"Catboost\", catboost.copy()),\n",
    "    (\"RandomForest\", clone(rf_model))\n",
    "]\n",
    "\n",
    "params = {\n",
    "    \"final_estimator\": [LinearRegression(), catboost.copy(), clone(rf_model)]\n",
    "}\n",
    "cv_search = GridSearchCV(StackingRegressor(stack_models), params, n_jobs = -1, verbose = 50)\n",
    "\n",
    "cv_search.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_stacking= cv_search.best_estimator_\n",
    "\n",
    "print(\"Best stacking params: \", best_stacking.get_params())\n",
    "\n",
    "start = timeit.default_timer()\n",
    "fitted_model, rmse_scores = measure_performance(best_stacking, x,y)\n",
    "end = timeit.default_timer()\n",
    "\n",
    "mean_rmse = np.mean(rmse_scores)\n",
    "std_rmse = np.std(rmse_scores)\n",
    "name = \"Stack Regressor Optimized\"\n",
    "elapsed = end - start\n",
    "print(\"Model \", name)\n",
    "print(\"mean \", mean_rmse)\n",
    "print(\"std \", std_rmse)\n",
    "print(\"elapsed: \", elapsed, \" seconds \")\n",
    "print(\"------------------------\\n\")\n",
    "model_scores.append({\"name\": name, \"rmse\": rmse_scores, \"elapsed_time\": elapsed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the score\n",
    "scores_df = convert_scores_to_pd(model_scores)\n",
    "\n",
    "print(scores_df.sort_values(by=\"mean\"))\n",
    "    \n",
    "scores_df.to_csv(os.path.join(ROOT, \"base_models\", \"09-16-2020-base.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
